{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZujC6ZsgHLdy",
        "outputId": "6935fe1b-d86a-4ac8-f69f-c3ee3c230bfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group\n",
            "0    190\n",
            "1    183\n",
            "Name: count, dtype: int64\n",
            "Training K-NN model...\n",
            "Results before hyperparameter tuning for K-NN model:\n",
            "K-NN model (without hyperparameter tuning) accuracy: 0.6933333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.66      0.65        32\n",
            "           1       0.74      0.72      0.73        43\n",
            "\n",
            "    accuracy                           0.69        75\n",
            "   macro avg       0.69      0.69      0.69        75\n",
            "weighted avg       0.69      0.69      0.69        75\n",
            "\n",
            "Duration without hyperparameter tuning: 0.0155 seconds\n",
            "Best parameter for K-NN: {'n_neighbors': 1}\n",
            "Best score for K-NN: 0.6372881355932203\n",
            "Results after hyperparameter tuning for K-NN model:\n",
            "K-NN model (with hyperparameter tuning) accuracy: 0.72\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.72      0.69        32\n",
            "           1       0.78      0.72      0.75        43\n",
            "\n",
            "    accuracy                           0.72        75\n",
            "   macro avg       0.72      0.72      0.72        75\n",
            "weighted avg       0.72      0.72      0.72        75\n",
            "\n",
            "Duration for hyperparameter tuning: 1.0283 seconds\n",
            "Duration with hyperparameter tuning: 0.0000 seconds\n",
            "Hyperparameter tuning improved the accuracy.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Training Logistic Regression model...\n",
            "Results before hyperparameter tuning for Logistic Regression model:\n",
            "Logistic Regression model (without hyperparameter tuning) accuracy: 0.88\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87        32\n",
            "           1       0.97      0.81      0.89        43\n",
            "\n",
            "    accuracy                           0.88        75\n",
            "   macro avg       0.88      0.89      0.88        75\n",
            "weighted avg       0.90      0.88      0.88        75\n",
            "\n",
            "Duration without hyperparameter tuning: 0.0226 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "c:\\Users\\Aslı Nur Karaman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameter for Logistic Regression: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best score for Logistic Regression: 0.963050847457627\n",
            "Results after hyperparameter tuning for Logistic Regression model:\n",
            "Logistic Regression model (with hyperparameter tuning) accuracy: 0.88\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87        32\n",
            "           1       0.97      0.81      0.89        43\n",
            "\n",
            "    accuracy                           0.88        75\n",
            "   macro avg       0.88      0.89      0.88        75\n",
            "weighted avg       0.90      0.88      0.88        75\n",
            "\n",
            "Duration for hyperparameter tuning: 3.1364 seconds\n",
            "Duration with hyperparameter tuning: 0.0130 seconds\n",
            "Hyperparameter tuning did not affect the accuracy.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Training Random Forest model...\n",
            "Results before hyperparameter tuning for Random Forest model:\n",
            "Random Forest model (without hyperparameter tuning) accuracy: 0.9066666666666666\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.97      0.90        32\n",
            "           1       0.97      0.86      0.91        43\n",
            "\n",
            "    accuracy                           0.91        75\n",
            "   macro avg       0.91      0.91      0.91        75\n",
            "weighted avg       0.92      0.91      0.91        75\n",
            "\n",
            "Duration without hyperparameter tuning: 0.2542 seconds\n",
            "Best parameter for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Best score for Random Forest: 0.963050847457627\n",
            "Results after hyperparameter tuning for Random Forest model:\n",
            "Random Forest model (with hyperparameter tuning) accuracy: 0.8933333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89        32\n",
            "           1       0.97      0.84      0.90        43\n",
            "\n",
            "    accuracy                           0.89        75\n",
            "   macro avg       0.89      0.90      0.89        75\n",
            "weighted avg       0.91      0.89      0.89        75\n",
            "\n",
            "Duration for hyperparameter tuning: 109.3339 seconds\n",
            "Duration with hyperparameter tuning: 0.1346 seconds\n",
            "Hyperparameter tuning decreased the accuracy.\n",
            "\n",
            "==================================================\n",
            "\n",
            "Training Naive Bayes model...\n",
            "Results before hyperparameter tuning for Naive Bayes model:\n",
            "Naive Bayes model (without hyperparameter tuning) accuracy: 0.88\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87        32\n",
            "           1       0.97      0.81      0.89        43\n",
            "\n",
            "    accuracy                           0.88        75\n",
            "   macro avg       0.88      0.89      0.88        75\n",
            "weighted avg       0.90      0.88      0.88        75\n",
            "\n",
            "Duration without hyperparameter tuning: 0.0030 seconds\n",
            "Best parameter for Naive Bayes: {'var_smoothing': 1e-09}\n",
            "Best score for Naive Bayes: 0.963050847457627\n",
            "Results after hyperparameter tuning for Naive Bayes model:\n",
            "Naive Bayes model (with hyperparameter tuning) accuracy: 0.88\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87        32\n",
            "           1       0.97      0.81      0.89        43\n",
            "\n",
            "    accuracy                           0.88        75\n",
            "   macro avg       0.88      0.89      0.88        75\n",
            "weighted avg       0.90      0.88      0.88        75\n",
            "\n",
            "Duration for hyperparameter tuning: 0.1400 seconds\n",
            "Duration with hyperparameter tuning: 0.0019 seconds\n",
            "Hyperparameter tuning did not affect the accuracy.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "csv_path = 'C:\\\\Users\\\\Aslı Nur Karaman\\\\Desktop\\\\DiseasePredictionCodes\\\\alzheimer.csv'\n",
        "alzheimer_data = pd.read_csv(csv_path)\n",
        "\n",
        "alzheimer_data['M/F'] = alzheimer_data['M/F'].map({'M': 0, 'F': 1})\n",
        "alzheimer_data.rename(columns={'M/F': 'M_F'}, inplace=True)\n",
        "alzheimer_data.Group = [0 if each == \"Nondemented\" else 1 for each in alzheimer_data.Group]\n",
        "mean_ses = alzheimer_data['SES'].mean()\n",
        "alzheimer_data['SES'].fillna(mean_ses, inplace=True)\n",
        "mean_mmse = alzheimer_data['MMSE'].mean()\n",
        "alzheimer_data['MMSE'].fillna(mean_mmse, inplace=True)\n",
        "\n",
        "class_distribution = alzheimer_data['Group'].value_counts()\n",
        "print(class_distribution)\n",
        "\n",
        "X = alzheimer_data.drop(\"Group\", axis=1)\n",
        "Y = alzheimer_data[\"Group\"]\n",
        "\n",
        "def compare_models(X, Y):\n",
        "    models = {\n",
        "        \"K-NN\": {\"model\": KNeighborsClassifier(), \"param_grid\": {\"n_neighbors\": range(1, 20)}},\n",
        "        \"Logistic Regression\": {\"model\": LogisticRegression(), \"param_grid\": {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}},\n",
        "        \"Random Forest\": {\"model\": RandomForestClassifier(), \"param_grid\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}},\n",
        "        \"Naive Bayes\": {\"model\": GaussianNB(), \"param_grid\": {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}}\n",
        "    }\n",
        "\n",
        "    for model_name, model_info in models.items():\n",
        "        print(f\"Training {model_name} model...\")\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "        model = model_info[\"model\"]\n",
        "        param_grid = model_info[\"param_grid\"]\n",
        "\n",
        "        print(f\"Results before hyperparameter tuning for {model_name} model:\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, Y_train)\n",
        "        Y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(Y_test, Y_pred)\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "        print(f\"{model_name} model (without hyperparameter tuning) accuracy:\", accuracy)\n",
        "        print(\"Classification Report:\\n\", classification_report(Y_test, Y_pred))\n",
        "        print(f\"Duration without hyperparameter tuning: {duration:.4f} seconds\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "        grid_search.fit(X_train, Y_train)\n",
        "        end_time = time.time()\n",
        "        grid_search_duration = end_time - start_time\n",
        "\n",
        "        best_params = grid_search.best_params_\n",
        "        best_score = grid_search.best_score_\n",
        "        print(f\"Best parameter for {model_name}:\", best_params)\n",
        "        print(f\"Best score for {model_name}:\", best_score)\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "        best_model = model.__class__(**best_params)\n",
        "        best_model.fit(X_train, Y_train)\n",
        "\n",
        "        print(f\"Results after hyperparameter tuning for {model_name} model:\")\n",
        "        Y_pred_tuned = best_model.predict(X_test)\n",
        "        accuracy_tuned = accuracy_score(Y_test, Y_pred_tuned)\n",
        "        end_time = time.time()\n",
        "        duration_tuned = end_time - start_time\n",
        "\n",
        "        print(f\"{model_name} model (with hyperparameter tuning) accuracy:\", accuracy_tuned)\n",
        "        print(\"Classification Report:\\n\", classification_report(Y_test, Y_pred_tuned))\n",
        "        print(f\"Duration for hyperparameter tuning: {grid_search_duration:.4f} seconds\")\n",
        "        print(f\"Duration with hyperparameter tuning: {duration_tuned:.4f} seconds\")\n",
        "\n",
        "        if accuracy_tuned > accuracy:\n",
        "            print(\"Hyperparameter tuning improved the accuracy.\")\n",
        "        elif accuracy_tuned < accuracy:\n",
        "            print(\"Hyperparameter tuning decreased the accuracy.\")\n",
        "        else:\n",
        "            print(\"Hyperparameter tuning did not affect the accuracy.\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "compare_models(X, Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Jv9T1GJgQSGy",
        "outputId": "e0767c3c-a45f-4ba8-f7cc-e695dea28123"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "rf_model.fit(X_train, Y_train)\n",
        "Y_pred = rf_model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Random Forest Model')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
